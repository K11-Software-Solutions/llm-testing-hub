# WeOptimize AI â€“ Red Teaming Harness

Baseline **Promptfoo** evaluation for the **WeOptimize.ai B2B Multi-LLM Assistant**.
Covers **security**, **bias**, **privacy**, and **harmful content** with reproducible configs, runners, and reports.

## ğŸ“‚ Repository Structure
```
weoptimize-redteam-harness/
â”œâ”€â”€ configs/                   # Promptfoo suites + model profiles
â”‚   â”œâ”€â”€ redteam-translation.yaml
â”‚   â””â”€â”€ model-profiles/
â”‚       â”œâ”€â”€ openai.gpt-4o-mini.yml
â”‚       â”œâ”€â”€ anthropic.claude-sonnet-4.yml
â”‚       â””â”€â”€ lmstudio.qwen3-1.7b.yml
â”œâ”€â”€ prompts/                   # corpora for harmful, pii, bola, injection, templates
â”œâ”€â”€ datasets/                  # synthetic datasets (no real PII)
â”œâ”€â”€ scripts/                   # runners, redaction, summarizers
â”œâ”€â”€ docs/                      # methodology, threat model, compliance mapping
â”œâ”€â”€ reports/                   # generated artifacts (html/json/csv/png)
â”œâ”€â”€ examples/                  # minimal working examples for quickstart
â””â”€â”€ README.md
```

## ğŸš€ Quickstart
```bash
npm install -g promptfoo
./scripts/run_promptfoo.sh configs/redteam-translation.yaml
promptfoo view
```

## ğŸ§ª Whatâ€™s Included
- Red-team suites (PII, BOLA, harmful content, injection)
- Model-graded assertions (refusal clarity, empathy)
- Provider profiles (OpenAI, Anthropic, LM Studio)
- Evidence outputs: HTML, JSON, CSV, PNG scorecards

## ğŸ›¡ï¸ Safety & Data Hygiene
- Use **synthetic** PII only
- Encode/store harmful prompts responsibly
- Never commit secrets; use `.env`/CI secrets
